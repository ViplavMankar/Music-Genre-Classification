{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 1690)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               865792    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,014,218\n",
      "Trainable params: 1,014,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\games\\anaconda_1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6990 samples, validate on 2996 samples\n",
      "Epoch 1/200\n",
      "6990/6990 [==============================] - 12s 2ms/step - loss: 22.9577 - accuracy: 0.1551 - val_loss: 3.4870 - val_accuracy: 0.2123\n",
      "Epoch 2/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 6.5625 - accuracy: 0.1482 - val_loss: 3.5019 - val_accuracy: 0.1195\n",
      "Epoch 3/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 4.5213 - accuracy: 0.1335 - val_loss: 3.4998 - val_accuracy: 0.1178\n",
      "Epoch 4/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 3.9703 - accuracy: 0.1373 - val_loss: 3.4646 - val_accuracy: 0.1245\n",
      "Epoch 5/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.7414 - accuracy: 0.1349 - val_loss: 3.4512 - val_accuracy: 0.1272\n",
      "Epoch 6/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.6361 - accuracy: 0.1425 - val_loss: 3.4446 - val_accuracy: 0.1292\n",
      "Epoch 7/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.5640 - accuracy: 0.1587 - val_loss: 3.4085 - val_accuracy: 0.1502\n",
      "Epoch 8/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.5065 - accuracy: 0.1644 - val_loss: 3.3672 - val_accuracy: 0.1709\n",
      "Epoch 9/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.4751 - accuracy: 0.1742 - val_loss: 3.3414 - val_accuracy: 0.1976\n",
      "Epoch 10/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.4095 - accuracy: 0.1941 - val_loss: 3.2906 - val_accuracy: 0.2236\n",
      "Epoch 11/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.3978 - accuracy: 0.2093 - val_loss: 3.2543 - val_accuracy: 0.2333\n",
      "Epoch 12/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.3345 - accuracy: 0.2143 - val_loss: 3.2552 - val_accuracy: 0.2387\n",
      "Epoch 13/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.3159 - accuracy: 0.2156 - val_loss: 3.2143 - val_accuracy: 0.2480\n",
      "Epoch 14/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.3018 - accuracy: 0.2270 - val_loss: 3.2042 - val_accuracy: 0.2493\n",
      "Epoch 15/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.2527 - accuracy: 0.2285 - val_loss: 3.1368 - val_accuracy: 0.2654\n",
      "Epoch 16/200\n",
      "6990/6990 [==============================] - 8s 1ms/step - loss: 3.2391 - accuracy: 0.2325 - val_loss: 3.1247 - val_accuracy: 0.2650\n",
      "Epoch 17/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.2218 - accuracy: 0.2340 - val_loss: 3.1120 - val_accuracy: 0.2647\n",
      "Epoch 18/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.1826 - accuracy: 0.2345 - val_loss: 3.0919 - val_accuracy: 0.2697\n",
      "Epoch 19/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.1381 - accuracy: 0.2484 - val_loss: 3.0587 - val_accuracy: 0.2720\n",
      "Epoch 20/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.1495 - accuracy: 0.2449 - val_loss: 3.0464 - val_accuracy: 0.2710\n",
      "Epoch 21/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 3.1158 - accuracy: 0.2443 - val_loss: 3.0206 - val_accuracy: 0.2734\n",
      "Epoch 22/200\n",
      "6990/6990 [==============================] - 8s 1ms/step - loss: 3.1057 - accuracy: 0.2511 - val_loss: 3.0080 - val_accuracy: 0.2757\n",
      "Epoch 23/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 3.0677 - accuracy: 0.2498 - val_loss: 2.9942 - val_accuracy: 0.2757\n",
      "Epoch 24/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 3.0567 - accuracy: 0.2491 - val_loss: 2.9523 - val_accuracy: 0.2797\n",
      "Epoch 25/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 3.0326 - accuracy: 0.2504 - val_loss: 2.9300 - val_accuracy: 0.2840\n",
      "Epoch 26/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 3.0004 - accuracy: 0.2588 - val_loss: 2.9518 - val_accuracy: 0.2787\n",
      "Epoch 27/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 2.9852 - accuracy: 0.2557 - val_loss: 2.8982 - val_accuracy: 0.2867\n",
      "Epoch 28/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 2.9598 - accuracy: 0.2554 - val_loss: 2.9106 - val_accuracy: 0.2784\n",
      "Epoch 29/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.9117 - accuracy: 0.2702 - val_loss: 2.8486 - val_accuracy: 0.2941\n",
      "Epoch 30/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.8939 - accuracy: 0.2698 - val_loss: 2.8365 - val_accuracy: 0.2911\n",
      "Epoch 31/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.8558 - accuracy: 0.2745 - val_loss: 2.7410 - val_accuracy: 0.3047\n",
      "Epoch 32/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.7949 - accuracy: 0.2755 - val_loss: 2.6530 - val_accuracy: 0.3027\n",
      "Epoch 33/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.7697 - accuracy: 0.2788 - val_loss: 2.6708 - val_accuracy: 0.3034\n",
      "Epoch 34/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.7187 - accuracy: 0.3024 - val_loss: 2.5751 - val_accuracy: 0.3541\n",
      "Epoch 35/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.6548 - accuracy: 0.3036 - val_loss: 2.5561 - val_accuracy: 0.3672\n",
      "Epoch 36/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.6667 - accuracy: 0.3052 - val_loss: 2.5081 - val_accuracy: 0.3655\n",
      "Epoch 37/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.6163 - accuracy: 0.3103 - val_loss: 2.5214 - val_accuracy: 0.3541\n",
      "Epoch 38/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.5763 - accuracy: 0.3210 - val_loss: 2.4823 - val_accuracy: 0.3755\n",
      "Epoch 39/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.5593 - accuracy: 0.3200 - val_loss: 2.4484 - val_accuracy: 0.3575\n",
      "Epoch 40/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 2.5212 - accuracy: 0.3279 - val_loss: 2.4053 - val_accuracy: 0.3795\n",
      "Epoch 41/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.4964 - accuracy: 0.3262 - val_loss: 2.3995 - val_accuracy: 0.4029\n",
      "Epoch 42/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 2.4763 - accuracy: 0.3362 - val_loss: 2.3581 - val_accuracy: 0.3965\n",
      "Epoch 43/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.4415 - accuracy: 0.3352 - val_loss: 2.3458 - val_accuracy: 0.4176\n",
      "Epoch 44/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 2.4228 - accuracy: 0.3398 - val_loss: 2.3060 - val_accuracy: 0.4009\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.3734 - accuracy: 0.3466 - val_loss: 2.2964 - val_accuracy: 0.4239\n",
      "Epoch 46/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.3313 - accuracy: 0.3627 - val_loss: 2.2734 - val_accuracy: 0.4189\n",
      "Epoch 47/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.3324 - accuracy: 0.3544 - val_loss: 2.2994 - val_accuracy: 0.4039\n",
      "Epoch 48/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.2877 - accuracy: 0.3631 - val_loss: 2.2219 - val_accuracy: 0.4286\n",
      "Epoch 49/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.2682 - accuracy: 0.3688 - val_loss: 2.2100 - val_accuracy: 0.4082\n",
      "Epoch 50/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.2405 - accuracy: 0.3662 - val_loss: 2.1756 - val_accuracy: 0.4339\n",
      "Epoch 51/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 2.2011 - accuracy: 0.3791 - val_loss: 2.2276 - val_accuracy: 0.4533\n",
      "Epoch 52/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.2155 - accuracy: 0.3850 - val_loss: 2.2257 - val_accuracy: 0.4152\n",
      "Epoch 53/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.1530 - accuracy: 0.4001 - val_loss: 2.1666 - val_accuracy: 0.4416\n",
      "Epoch 54/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.1293 - accuracy: 0.4044 - val_loss: 2.1269 - val_accuracy: 0.4609\n",
      "Epoch 55/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.0884 - accuracy: 0.4199 - val_loss: 2.0797 - val_accuracy: 0.4579\n",
      "Epoch 56/200\n",
      "6990/6990 [==============================] - 8s 1ms/step - loss: 2.0749 - accuracy: 0.4176 - val_loss: 2.0858 - val_accuracy: 0.4556\n",
      "Epoch 57/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 2.0380 - accuracy: 0.4136 - val_loss: 2.0201 - val_accuracy: 0.4753\n",
      "Epoch 58/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 2.0092 - accuracy: 0.4263 - val_loss: 2.0458 - val_accuracy: 0.4616\n",
      "Epoch 59/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.9946 - accuracy: 0.4416 - val_loss: 2.0291 - val_accuracy: 0.4656\n",
      "Epoch 60/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.9560 - accuracy: 0.4491 - val_loss: 1.9961 - val_accuracy: 0.4786\n",
      "Epoch 61/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.9443 - accuracy: 0.4454 - val_loss: 2.0662 - val_accuracy: 0.4619\n",
      "Epoch 62/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.9020 - accuracy: 0.4548 - val_loss: 2.0156 - val_accuracy: 0.4760\n",
      "Epoch 63/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.8981 - accuracy: 0.4552 - val_loss: 1.9605 - val_accuracy: 0.4880\n",
      "Epoch 64/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.8641 - accuracy: 0.4675 - val_loss: 1.9805 - val_accuracy: 0.4873\n",
      "Epoch 65/200\n",
      "6990/6990 [==============================] - 12s 2ms/step - loss: 1.8575 - accuracy: 0.4629 - val_loss: 1.9336 - val_accuracy: 0.5050\n",
      "Epoch 66/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 1.8305 - accuracy: 0.4721 - val_loss: 1.9003 - val_accuracy: 0.5030\n",
      "Epoch 67/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.8174 - accuracy: 0.4758 - val_loss: 1.9197 - val_accuracy: 0.4933\n",
      "Epoch 68/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.7860 - accuracy: 0.4868 - val_loss: 1.9214 - val_accuracy: 0.5017\n",
      "Epoch 69/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 1.7739 - accuracy: 0.4856 - val_loss: 1.9260 - val_accuracy: 0.4893\n",
      "Epoch 70/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.7415 - accuracy: 0.4961 - val_loss: 1.8932 - val_accuracy: 0.5140\n",
      "Epoch 71/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.7482 - accuracy: 0.5004 - val_loss: 1.8665 - val_accuracy: 0.5040\n",
      "Epoch 72/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.6907 - accuracy: 0.5087 - val_loss: 1.8751 - val_accuracy: 0.5144\n",
      "Epoch 73/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.6991 - accuracy: 0.5152 - val_loss: 1.9057 - val_accuracy: 0.5150\n",
      "Epoch 74/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.6673 - accuracy: 0.5290 - val_loss: 1.8904 - val_accuracy: 0.5087\n",
      "Epoch 75/200\n",
      "6990/6990 [==============================] - 8s 1ms/step - loss: 1.6503 - accuracy: 0.5288 - val_loss: 1.8184 - val_accuracy: 0.5280\n",
      "Epoch 76/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.6317 - accuracy: 0.5368 - val_loss: 1.8600 - val_accuracy: 0.5250\n",
      "Epoch 77/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.6123 - accuracy: 0.5385 - val_loss: 1.8121 - val_accuracy: 0.5340\n",
      "Epoch 78/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.5916 - accuracy: 0.5572 - val_loss: 1.8286 - val_accuracy: 0.5317\n",
      "Epoch 79/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.5497 - accuracy: 0.5668 - val_loss: 1.7647 - val_accuracy: 0.5370\n",
      "Epoch 80/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.5353 - accuracy: 0.5628 - val_loss: 1.8144 - val_accuracy: 0.5397\n",
      "Epoch 81/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 1.5235 - accuracy: 0.5624 - val_loss: 1.8065 - val_accuracy: 0.5360\n",
      "Epoch 82/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.4945 - accuracy: 0.5738 - val_loss: 1.7628 - val_accuracy: 0.5487\n",
      "Epoch 83/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.4733 - accuracy: 0.5715 - val_loss: 1.8418 - val_accuracy: 0.5377\n",
      "Epoch 84/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.4495 - accuracy: 0.5866 - val_loss: 1.7512 - val_accuracy: 0.5384\n",
      "Epoch 85/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.4385 - accuracy: 0.5966 - val_loss: 1.7631 - val_accuracy: 0.5517\n",
      "Epoch 86/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.4531 - accuracy: 0.5934 - val_loss: 1.7446 - val_accuracy: 0.5340\n",
      "Epoch 87/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.4136 - accuracy: 0.5986 - val_loss: 1.7690 - val_accuracy: 0.5447\n",
      "Epoch 88/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.3932 - accuracy: 0.6137 - val_loss: 1.7620 - val_accuracy: 0.5587\n",
      "Epoch 89/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.3726 - accuracy: 0.6123 - val_loss: 1.7765 - val_accuracy: 0.5454\n",
      "Epoch 90/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.3457 - accuracy: 0.6186 - val_loss: 1.7509 - val_accuracy: 0.5521\n",
      "Epoch 91/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.3312 - accuracy: 0.6239 - val_loss: 1.7690 - val_accuracy: 0.5651\n",
      "Epoch 92/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.3178 - accuracy: 0.6292 - val_loss: 1.7208 - val_accuracy: 0.5644\n",
      "Epoch 93/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.3100 - accuracy: 0.6283 - val_loss: 1.7267 - val_accuracy: 0.5648\n",
      "Epoch 94/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.2850 - accuracy: 0.6333 - val_loss: 1.7749 - val_accuracy: 0.5541\n",
      "Epoch 95/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.2985 - accuracy: 0.6396 - val_loss: 1.6939 - val_accuracy: 0.5768\n",
      "Epoch 96/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.2592 - accuracy: 0.6471 - val_loss: 1.7122 - val_accuracy: 0.5684\n",
      "Epoch 97/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.2498 - accuracy: 0.6512 - val_loss: 1.7676 - val_accuracy: 0.5734\n",
      "Epoch 98/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.2349 - accuracy: 0.6662 - val_loss: 1.7136 - val_accuracy: 0.5704\n",
      "Epoch 99/200\n",
      "6990/6990 [==============================] - 8s 1ms/step - loss: 1.2257 - accuracy: 0.6609 - val_loss: 1.6772 - val_accuracy: 0.5724\n",
      "Epoch 100/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.2085 - accuracy: 0.6675 - val_loss: 1.7315 - val_accuracy: 0.5784\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.1826 - accuracy: 0.6717 - val_loss: 1.7396 - val_accuracy: 0.5798\n",
      "Epoch 102/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.1872 - accuracy: 0.6661 - val_loss: 1.6774 - val_accuracy: 0.5885\n",
      "Epoch 103/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.1728 - accuracy: 0.6732 - val_loss: 1.6988 - val_accuracy: 0.5828\n",
      "Epoch 104/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.1526 - accuracy: 0.6825 - val_loss: 1.7023 - val_accuracy: 0.5818\n",
      "Epoch 105/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.1684 - accuracy: 0.6810 - val_loss: 1.6854 - val_accuracy: 0.5868\n",
      "Epoch 106/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.1324 - accuracy: 0.6924 - val_loss: 1.7163 - val_accuracy: 0.5848\n",
      "Epoch 107/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.1275 - accuracy: 0.6914 - val_loss: 1.6772 - val_accuracy: 0.5844\n",
      "Epoch 108/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.1103 - accuracy: 0.6966 - val_loss: 1.7008 - val_accuracy: 0.5955\n",
      "Epoch 109/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.1030 - accuracy: 0.7100 - val_loss: 1.7256 - val_accuracy: 0.5854\n",
      "Epoch 110/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0962 - accuracy: 0.7096 - val_loss: 1.6716 - val_accuracy: 0.5911\n",
      "Epoch 111/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 1.0746 - accuracy: 0.7117 - val_loss: 1.6956 - val_accuracy: 0.5911\n",
      "Epoch 112/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0372 - accuracy: 0.7239 - val_loss: 1.6477 - val_accuracy: 0.6095\n",
      "Epoch 113/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0589 - accuracy: 0.7189 - val_loss: 1.7341 - val_accuracy: 0.5744\n",
      "Epoch 114/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0284 - accuracy: 0.7296 - val_loss: 1.6460 - val_accuracy: 0.6055\n",
      "Epoch 115/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0349 - accuracy: 0.7300 - val_loss: 1.7172 - val_accuracy: 0.5985\n",
      "Epoch 116/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0241 - accuracy: 0.7349 - val_loss: 1.6710 - val_accuracy: 0.5918\n",
      "Epoch 117/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0254 - accuracy: 0.7296 - val_loss: 1.7010 - val_accuracy: 0.5981\n",
      "Epoch 118/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0067 - accuracy: 0.7442 - val_loss: 1.6746 - val_accuracy: 0.5965\n",
      "Epoch 119/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 1.0080 - accuracy: 0.7363 - val_loss: 1.7290 - val_accuracy: 0.5921\n",
      "Epoch 120/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9678 - accuracy: 0.7481 - val_loss: 1.6785 - val_accuracy: 0.6068\n",
      "Epoch 121/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9618 - accuracy: 0.7539 - val_loss: 1.7087 - val_accuracy: 0.5995\n",
      "Epoch 122/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9538 - accuracy: 0.7508 - val_loss: 1.7705 - val_accuracy: 0.5948\n",
      "Epoch 123/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9521 - accuracy: 0.7558 - val_loss: 1.7547 - val_accuracy: 0.6055\n",
      "Epoch 124/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9462 - accuracy: 0.7552 - val_loss: 1.7397 - val_accuracy: 0.6055\n",
      "Epoch 125/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9420 - accuracy: 0.7605 - val_loss: 1.8369 - val_accuracy: 0.6028\n",
      "Epoch 126/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9408 - accuracy: 0.7674 - val_loss: 1.7780 - val_accuracy: 0.6008\n",
      "Epoch 127/200\n",
      "6990/6990 [==============================] - 9s 1ms/step - loss: 0.9125 - accuracy: 0.7714 - val_loss: 1.7686 - val_accuracy: 0.6108\n",
      "Epoch 128/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8994 - accuracy: 0.7757 - val_loss: 1.7721 - val_accuracy: 0.5971\n",
      "Epoch 129/200\n",
      "6990/6990 [==============================] - 12s 2ms/step - loss: 0.9013 - accuracy: 0.7728 - val_loss: 1.7670 - val_accuracy: 0.6045\n",
      "Epoch 130/200\n",
      "6990/6990 [==============================] - 12s 2ms/step - loss: 0.9163 - accuracy: 0.7690 - val_loss: 1.7750 - val_accuracy: 0.5958\n",
      "Epoch 131/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8727 - accuracy: 0.7813 - val_loss: 1.6902 - val_accuracy: 0.6098\n",
      "Epoch 132/200\n",
      "6990/6990 [==============================] - 10s 2ms/step - loss: 0.8726 - accuracy: 0.7884 - val_loss: 1.7339 - val_accuracy: 0.6132\n",
      "Epoch 133/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 0.8663 - accuracy: 0.7878 - val_loss: 1.7469 - val_accuracy: 0.6078\n",
      "Epoch 134/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8650 - accuracy: 0.7873 - val_loss: 1.7149 - val_accuracy: 0.6115\n",
      "Epoch 135/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8662 - accuracy: 0.7873 - val_loss: 1.7542 - val_accuracy: 0.6048\n",
      "Epoch 136/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8368 - accuracy: 0.7967 - val_loss: 1.7538 - val_accuracy: 0.6128\n",
      "Epoch 137/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8370 - accuracy: 0.7956 - val_loss: 1.6929 - val_accuracy: 0.6178\n",
      "Epoch 138/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8590 - accuracy: 0.7930 - val_loss: 1.7075 - val_accuracy: 0.6051\n",
      "Epoch 139/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8050 - accuracy: 0.8046 - val_loss: 1.7523 - val_accuracy: 0.6245\n",
      "Epoch 140/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 0.8138 - accuracy: 0.8040 - val_loss: 1.6821 - val_accuracy: 0.6125\n",
      "Epoch 141/200\n",
      "6990/6990 [==============================] - 11s 2ms/step - loss: 0.8128 - accuracy: 0.8086 - val_loss: 1.7267 - val_accuracy: 0.6091\n",
      "Epoch 142/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 0.7988 - accuracy: 0.8077 - val_loss: 1.6802 - val_accuracy: 0.6205\n",
      "Epoch 143/200\n",
      "6990/6990 [==============================] - 10s 1ms/step - loss: 0.7867 - accuracy: 0.8107 - val_loss: 1.6986 - val_accuracy: 0.6278\n",
      "Epoch 144/200\n",
      "6990/6990 [==============================] - 7s 1ms/step - loss: 0.7756 - accuracy: 0.8220 - val_loss: 1.7224 - val_accuracy: 0.6145\n",
      "Epoch 145/200\n",
      "6990/6990 [==============================] - 6s 796us/step - loss: 0.8091 - accuracy: 0.8144 - val_loss: 1.7254 - val_accuracy: 0.6098\n",
      "Epoch 146/200\n",
      "6990/6990 [==============================] - 6s 800us/step - loss: 0.7968 - accuracy: 0.8100 - val_loss: 1.7059 - val_accuracy: 0.6202\n",
      "Epoch 147/200\n",
      "6990/6990 [==============================] - 6s 836us/step - loss: 0.7568 - accuracy: 0.8203 - val_loss: 1.7724 - val_accuracy: 0.6115\n",
      "Epoch 148/200\n",
      "6990/6990 [==============================] - 6s 831us/step - loss: 0.7631 - accuracy: 0.8255 - val_loss: 1.7123 - val_accuracy: 0.6225\n",
      "Epoch 149/200\n",
      "6990/6990 [==============================] - 6s 840us/step - loss: 0.7508 - accuracy: 0.8216 - val_loss: 1.7612 - val_accuracy: 0.6041\n",
      "Epoch 150/200\n",
      "6990/6990 [==============================] - 6s 912us/step - loss: 0.7512 - accuracy: 0.8255 - val_loss: 1.7148 - val_accuracy: 0.6192\n",
      "Epoch 151/200\n",
      "6990/6990 [==============================] - 6s 891us/step - loss: 0.7602 - accuracy: 0.8220 - val_loss: 1.7781 - val_accuracy: 0.6055\n",
      "Epoch 152/200\n",
      "6990/6990 [==============================] - 6s 922us/step - loss: 0.7619 - accuracy: 0.8196 - val_loss: 1.7050 - val_accuracy: 0.6205\n",
      "Epoch 153/200\n",
      "6990/6990 [==============================] - 6s 919us/step - loss: 0.7521 - accuracy: 0.8278 - val_loss: 1.7211 - val_accuracy: 0.6168\n",
      "Epoch 154/200\n",
      "6990/6990 [==============================] - 7s 946us/step - loss: 0.7405 - accuracy: 0.8269 - val_loss: 1.7071 - val_accuracy: 0.6232\n",
      "Epoch 155/200\n",
      "6990/6990 [==============================] - 6s 879us/step - loss: 0.7596 - accuracy: 0.8269 - val_loss: 1.7159 - val_accuracy: 0.6228\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990/6990 [==============================] - 6s 916us/step - loss: 0.7394 - accuracy: 0.8303 - val_loss: 1.7264 - val_accuracy: 0.6252\n",
      "Epoch 157/200\n",
      "6990/6990 [==============================] - 6s 813us/step - loss: 0.7346 - accuracy: 0.8336 - val_loss: 1.8082 - val_accuracy: 0.6125\n",
      "Epoch 158/200\n",
      "6990/6990 [==============================] - 6s 843us/step - loss: 0.7339 - accuracy: 0.8253 - val_loss: 1.7556 - val_accuracy: 0.6145\n",
      "Epoch 159/200\n",
      "6990/6990 [==============================] - 6s 868us/step - loss: 0.6961 - accuracy: 0.8443 - val_loss: 1.7368 - val_accuracy: 0.6208\n",
      "Epoch 160/200\n",
      "6990/6990 [==============================] - 6s 854us/step - loss: 0.6902 - accuracy: 0.8452 - val_loss: 1.8214 - val_accuracy: 0.6132\n",
      "Epoch 161/200\n",
      "6990/6990 [==============================] - 6s 835us/step - loss: 0.6980 - accuracy: 0.8476 - val_loss: 1.7566 - val_accuracy: 0.6208\n",
      "Epoch 162/200\n",
      "6990/6990 [==============================] - 6s 846us/step - loss: 0.7122 - accuracy: 0.8411 - val_loss: 1.8030 - val_accuracy: 0.6051\n",
      "Epoch 163/200\n",
      "6990/6990 [==============================] - 6s 793us/step - loss: 0.6983 - accuracy: 0.8399 - val_loss: 1.7060 - val_accuracy: 0.6188\n",
      "Epoch 164/200\n",
      "6990/6990 [==============================] - 6s 824us/step - loss: 0.7034 - accuracy: 0.8412 - val_loss: 1.7244 - val_accuracy: 0.6275\n",
      "Epoch 165/200\n",
      "6990/6990 [==============================] - 6s 857us/step - loss: 0.6861 - accuracy: 0.8445 - val_loss: 1.7533 - val_accuracy: 0.6198\n",
      "Epoch 166/200\n",
      "6990/6990 [==============================] - 6s 848us/step - loss: 0.6900 - accuracy: 0.8488 - val_loss: 1.8095 - val_accuracy: 0.6258\n",
      "Epoch 167/200\n",
      "6990/6990 [==============================] - 6s 847us/step - loss: 0.6955 - accuracy: 0.8449 - val_loss: 1.7196 - val_accuracy: 0.6198\n",
      "Epoch 168/200\n",
      "6990/6990 [==============================] - 6s 860us/step - loss: 0.6838 - accuracy: 0.8505 - val_loss: 1.7038 - val_accuracy: 0.6205\n",
      "Epoch 169/200\n",
      "6990/6990 [==============================] - 6s 912us/step - loss: 0.6966 - accuracy: 0.8478 - val_loss: 1.8161 - val_accuracy: 0.6185\n",
      "Epoch 170/200\n",
      "6990/6990 [==============================] - 6s 916us/step - loss: 0.6635 - accuracy: 0.8548 - val_loss: 1.7894 - val_accuracy: 0.6172\n",
      "Epoch 171/200\n",
      "6990/6990 [==============================] - 6s 879us/step - loss: 0.6493 - accuracy: 0.8577 - val_loss: 1.7393 - val_accuracy: 0.6272\n",
      "Epoch 172/200\n",
      "6990/6990 [==============================] - 6s 831us/step - loss: 0.6601 - accuracy: 0.8525 - val_loss: 1.7735 - val_accuracy: 0.6232\n",
      "Epoch 173/200\n",
      "6990/6990 [==============================] - 6s 898us/step - loss: 0.6427 - accuracy: 0.8618 - val_loss: 1.7451 - val_accuracy: 0.6205\n",
      "Epoch 174/200\n",
      "6990/6990 [==============================] - 6s 884us/step - loss: 0.6428 - accuracy: 0.8621 - val_loss: 1.7826 - val_accuracy: 0.6132\n",
      "Epoch 175/200\n",
      "6990/6990 [==============================] - 7s 1ms/step - loss: 0.6583 - accuracy: 0.8557 - val_loss: 1.7544 - val_accuracy: 0.6275\n",
      "Epoch 176/200\n",
      "6990/6990 [==============================] - 7s 982us/step - loss: 0.6566 - accuracy: 0.8572 - val_loss: 1.7474 - val_accuracy: 0.6305\n",
      "Epoch 177/200\n",
      "6990/6990 [==============================] - 7s 1ms/step - loss: 0.6436 - accuracy: 0.8587 - val_loss: 1.7664 - val_accuracy: 0.6262\n",
      "Epoch 178/200\n",
      "6990/6990 [==============================] - 6s 851us/step - loss: 0.6312 - accuracy: 0.8670 - val_loss: 1.7625 - val_accuracy: 0.6238\n",
      "Epoch 179/200\n",
      "6990/6990 [==============================] - 6s 835us/step - loss: 0.6327 - accuracy: 0.8690 - val_loss: 1.7580 - val_accuracy: 0.6242\n",
      "Epoch 180/200\n",
      "6990/6990 [==============================] - 6s 870us/step - loss: 0.6237 - accuracy: 0.8701 - val_loss: 1.7351 - val_accuracy: 0.6305\n",
      "Epoch 181/200\n",
      "6990/6990 [==============================] - 7s 942us/step - loss: 0.6486 - accuracy: 0.8644 - val_loss: 1.7053 - val_accuracy: 0.6305\n",
      "Epoch 182/200\n",
      "6990/6990 [==============================] - 6s 863us/step - loss: 0.6428 - accuracy: 0.8652 - val_loss: 1.7293 - val_accuracy: 0.6265\n",
      "Epoch 183/200\n",
      "6990/6990 [==============================] - 6s 876us/step - loss: 0.6111 - accuracy: 0.8734 - val_loss: 1.7531 - val_accuracy: 0.6192\n",
      "Epoch 184/200\n",
      "6990/6990 [==============================] - 6s 880us/step - loss: 0.6485 - accuracy: 0.8619 - val_loss: 1.7096 - val_accuracy: 0.6302\n",
      "Epoch 185/200\n",
      "6990/6990 [==============================] - 6s 894us/step - loss: 0.6114 - accuracy: 0.8738 - val_loss: 1.8020 - val_accuracy: 0.6252\n",
      "Epoch 186/200\n",
      "6990/6990 [==============================] - 7s 967us/step - loss: 0.6092 - accuracy: 0.8725 - val_loss: 1.7733 - val_accuracy: 0.6252\n",
      "Epoch 187/200\n",
      "6990/6990 [==============================] - 6s 880us/step - loss: 0.6131 - accuracy: 0.8721 - val_loss: 1.7810 - val_accuracy: 0.6212\n",
      "Epoch 188/200\n",
      "6990/6990 [==============================] - 6s 926us/step - loss: 0.6155 - accuracy: 0.8737 - val_loss: 1.7769 - val_accuracy: 0.6145\n",
      "Epoch 189/200\n",
      "6990/6990 [==============================] - 6s 924us/step - loss: 0.5937 - accuracy: 0.8804 - val_loss: 1.8333 - val_accuracy: 0.6108\n",
      "Epoch 190/200\n",
      "6990/6990 [==============================] - 7s 938us/step - loss: 0.6107 - accuracy: 0.8734 - val_loss: 1.7783 - val_accuracy: 0.6128\n",
      "Epoch 191/200\n",
      "6990/6990 [==============================] - 6s 908us/step - loss: 0.6005 - accuracy: 0.8771 - val_loss: 1.6916 - val_accuracy: 0.6258\n",
      "Epoch 192/200\n",
      "6990/6990 [==============================] - 6s 904us/step - loss: 0.6163 - accuracy: 0.8742 - val_loss: 1.8161 - val_accuracy: 0.6202\n",
      "Epoch 193/200\n",
      "6990/6990 [==============================] - 6s 911us/step - loss: 0.5949 - accuracy: 0.8793 - val_loss: 1.7516 - val_accuracy: 0.6315\n",
      "Epoch 194/200\n",
      "6990/6990 [==============================] - 6s 911us/step - loss: 0.5822 - accuracy: 0.8841 - val_loss: 1.7239 - val_accuracy: 0.6348\n",
      "Epoch 195/200\n",
      "6990/6990 [==============================] - 6s 924us/step - loss: 0.6032 - accuracy: 0.8731 - val_loss: 1.7708 - val_accuracy: 0.6272\n",
      "Epoch 196/200\n",
      "6990/6990 [==============================] - 7s 938us/step - loss: 0.5909 - accuracy: 0.8785 - val_loss: 1.8323 - val_accuracy: 0.6158\n",
      "Epoch 197/200\n",
      "6990/6990 [==============================] - 7s 950us/step - loss: 0.5722 - accuracy: 0.8871 - val_loss: 1.7250 - val_accuracy: 0.6302\n",
      "Epoch 198/200\n",
      "6990/6990 [==============================] - 6s 899us/step - loss: 0.6033 - accuracy: 0.8755 - val_loss: 1.6794 - val_accuracy: 0.6258\n",
      "Epoch 199/200\n",
      "6990/6990 [==============================] - 7s 977us/step - loss: 0.5837 - accuracy: 0.8871 - val_loss: 1.7716 - val_accuracy: 0.6228\n",
      "Epoch 200/200\n",
      "6990/6990 [==============================] - 6s 926us/step - loss: 0.5633 - accuracy: 0.8883 - val_loss: 1.8553 - val_accuracy: 0.6218\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"dataset.json\"\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    \n",
    "    inputs = np.array(data[\"mfcc\"])\n",
    "    targets = np.array(data[\"labels\"])\n",
    "    return inputs, targets\n",
    "\n",
    "def predict(model, X, y):\n",
    "    \n",
    "    X = X[np.newaxis,...]\n",
    "    prediction = model.predict(X)\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    print(\"Expected index : {}, \\nPredicted index : {}\".format(y, predicted_index))\n",
    "    \n",
    "def plot_history(history):\n",
    "    \n",
    "    fig, axs= plt.subplots(2)\n",
    "    \n",
    "    axs[0].plot(history.history[\"accuracy\"], label= \"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label= \"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc= \"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "    \n",
    "    axs[1].plot(history.history[\"loss\"], label= \"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label= \"test error\")\n",
    "    axs[1].set_ylabel(\"error\")\n",
    "    axs[1].set_xlabel(\"epoch\")\n",
    "    axs[1].legend(loc= \"upper right\")\n",
    "    axs[1].set_title(\"error eval\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    inputs, targets = load_data(DATASET_PATH)\n",
    "    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size= 0.3)\n",
    "    \n",
    "    model= keras.Sequential([\n",
    "    \n",
    "        keras.layers.Flatten(input_shape= (inputs.shape[1], inputs.shape[2])),\n",
    "        \n",
    "        keras.layers.Dense(512, activation= \"relu\", kernel_regularizer= keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Dense(256, activation= \"relu\", kernel_regularizer= keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Dense(64, activation= \"relu\", kernel_regularizer= keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Dense(10, activation= \"softmax\")\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate= 0.0001)\n",
    "    model.compile(optimizer= optimizer, \n",
    "                  loss= \"sparse_categorical_crossentropy\", \n",
    "                  metrics= [\"accuracy\"])\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(inputs_train, targets_train, validation_data= (inputs_test, targets_test), epochs= 200, batch_size= 32)\n",
    "    #print(history)\n",
    "    #plot_history(history)\n",
    "    \n",
    "    X = inputs_test[4]\n",
    "    y = targets_test[4]\n",
    "    predict(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 5, \n",
      "Predicted index : [1]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 0, \n",
      "Predicted index : [9]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 2, \n",
      "Predicted index : [9]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 2, \n",
      "Predicted index : [9]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 2, \n",
      "Predicted index : [5]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 5, \n",
      "Predicted index : [9]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "\n",
      "right : 94, \n",
      "wrong : 6\n",
      "Accuracy : 0.94\n"
     ]
    }
   ],
   "source": [
    "def predict_it(model, X, y, count):\n",
    "    \n",
    "    X = X[np.newaxis,...]\n",
    "    prediction = model.predict(X)\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    print(\"Expected index : {}, \\nPredicted index : {}\".format(y, predicted_index))\n",
    "    if y==predicted_index:\n",
    "        count+=1\n",
    "    return count\n",
    "\n",
    "count = 0\n",
    "num = 100\n",
    "for i in range(num):\n",
    "    X = inputs_train[i]\n",
    "    y = targets_train[i]\n",
    "    count=predict_it(model, X, y, count)\n",
    "    \n",
    "print()\n",
    "print(\"right : {}, \\nwrong : {}\\nAccuracy : {}\".format(count, num-count, count/num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load successfully\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Load successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 3, \n",
      "Predicted index : [9]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 9, \n",
      "Predicted index : [0]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 7, \n",
      "Predicted index : [2]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 5, \n",
      "Predicted index : [1]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 3, \n",
      "Predicted index : [6]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 2, \n",
      "Predicted index : [7]\n",
      "Expected index : 5, \n",
      "Predicted index : [4]\n",
      "Expected index : 7, \n",
      "Predicted index : [9]\n",
      "Expected index : 7, \n",
      "Predicted index : [2]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 8, \n",
      "Predicted index : [5]\n",
      "Expected index : 9, \n",
      "Predicted index : [0]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 6, \n",
      "Predicted index : [9]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 7, \n",
      "Predicted index : [4]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 9, \n",
      "Predicted index : [6]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 2, \n",
      "Predicted index : [8]\n",
      "Expected index : 8, \n",
      "Predicted index : [3]\n",
      "Expected index : 8, \n",
      "Predicted index : [1]\n",
      "Expected index : 7, \n",
      "Predicted index : [3]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 3, \n",
      "Predicted index : [3]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 0, \n",
      "Predicted index : [2]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 6, \n",
      "Predicted index : [6]\n",
      "Expected index : 5, \n",
      "Predicted index : [0]\n",
      "Expected index : 8, \n",
      "Predicted index : [8]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 8, \n",
      "Predicted index : [3]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 5, \n",
      "Predicted index : [1]\n",
      "Expected index : 9, \n",
      "Predicted index : [6]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 0, \n",
      "Predicted index : [3]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 3, \n",
      "Predicted index : [2]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 7, \n",
      "Predicted index : [3]\n",
      "Expected index : 2, \n",
      "Predicted index : [9]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 4, \n",
      "Predicted index : [3]\n",
      "Expected index : 0, \n",
      "Predicted index : [0]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 4, \n",
      "Predicted index : [8]\n",
      "Expected index : 4, \n",
      "Predicted index : [4]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 9, \n",
      "Predicted index : [7]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 2, \n",
      "Predicted index : [0]\n",
      "Expected index : 8, \n",
      "Predicted index : [6]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 7, \n",
      "Predicted index : [7]\n",
      "Expected index : 5, \n",
      "Predicted index : [5]\n",
      "Expected index : 7, \n",
      "Predicted index : [4]\n",
      "Expected index : 9, \n",
      "Predicted index : [9]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 9, \n",
      "Predicted index : [0]\n",
      "Expected index : 2, \n",
      "Predicted index : [2]\n",
      "Expected index : 5, \n",
      "Predicted index : [4]\n",
      "Expected index : 8, \n",
      "Predicted index : [9]\n",
      "Expected index : 1, \n",
      "Predicted index : [1]\n",
      "Expected index : 2, \n",
      "Predicted index : [0]\n",
      "Expected index : 9, \n",
      "Predicted index : [2]\n",
      "Expected index : 2, \n",
      "Predicted index : [9]\n",
      "Expected index : 7, \n",
      "Predicted index : [8]\n",
      "\n",
      "right : 60, \n",
      "wrong : 40\n",
      "Accuracy : 0.6\n"
     ]
    }
   ],
   "source": [
    "def predict_it(model, X, y, count):\n",
    "    \n",
    "    X = X[np.newaxis,...]\n",
    "    prediction = model.predict(X)\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "    print(\"Expected index : {}, \\nPredicted index : {}\".format(y, predicted_index))\n",
    "    if y==predicted_index:\n",
    "        count+=1\n",
    "    return count\n",
    "\n",
    "count = 0\n",
    "num = 100\n",
    "for i in range(num):\n",
    "    X = inputs_test[i]\n",
    "    y = targets_test[i]\n",
    "    count=predict_it(loaded_model , X, y, count)\n",
    "    \n",
    "print()\n",
    "print(\"right : {}, \\nwrong : {}\\nAccuracy : {}\".format(count, num-count, count/num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
